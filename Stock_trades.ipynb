{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GN1HaE-ezatL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_O5XGHUnzatM"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T681XihlzatM",
    "outputId": "ef368f19-51f9-4bf0-bc46-40d618124df7"
   },
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "N41EOPjGzatN",
    "outputId": "e6e1f732-4569-4498-abfd-6a1d7a9db464"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7qiGyH7CzatN",
    "outputId": "40769b76-65f5-4660-98fe-8e4534d73ac8"
   },
   "outputs": [],
   "source": [
    "df[\"Trades\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "avhHPrrpzatN"
   },
   "outputs": [],
   "source": [
    "# more than 50% data of trades is null, therefore dropping it from the dataset\n",
    "df = df.drop(columns = ['Trades','Series', 'Symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dGOm8iRYzatO"
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset = ['Deliverable Volume'], axis= 0)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "isTWkTqxzatO"
   },
   "outputs": [],
   "source": [
    "#Turnover = VWAP*Volume, therfore dropping it\n",
    "df = df.drop(columns = ['Turnover'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ojdpaCOBzatO"
   },
   "outputs": [],
   "source": [
    "# Convert 'Date' column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bbAIACIHzatO"
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['Year', 'Month', 'Day'], ascending=True)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "Y86XXY-4zatP",
    "outputId": "0405d6db-1ab9-487b-c44c-8293af86950a"
   },
   "outputs": [],
   "source": [
    "year_counts = df['Year'].value_counts().sort_index()  # This counts the entries per year and sorts by year\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "year_counts.plot(kind='bar', color='blue')\n",
    "plt.title('Count of Entries per Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "id": "IRSNEUZkzatP",
    "outputId": "4d378a6b-bcc2-482a-accf-65c13181c4b1"
   },
   "outputs": [],
   "source": [
    "#  Calculate the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "plt.figure(figsize=(30, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Correlation Matrix Heatmap')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m784YdbUzatP"
   },
   "outputs": [],
   "source": [
    "#Due to columns with highly correlated with other columns it is preferable to drop them\n",
    "df = df.drop(columns = ['Last', 'Date', 'Deliverable Volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GQfHNu8EW9yS",
    "outputId": "cc73ec25-5ecc-4bec-b1b7-03d5bd97d3f4"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TmV9vutNlG8s",
    "outputId": "c4850f1c-6662-43a3-b331-327ca74226b8"
   },
   "outputs": [],
   "source": [
    "!pip install pandas-ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "3l1tk5V80W4f",
    "outputId": "2f72c836-d169-436d-9cc3-47fa1b8567d0"
   },
   "outputs": [],
   "source": [
    "!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
    "!tar -xzvf ta-lib-0.4.0-src.tar.gz\n",
    "%cd ta-lib\n",
    "!./configure --prefix=/usr\n",
    "!make\n",
    "!make install\n",
    "!pip install TA-Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWAOnuXez1Y2"
   },
   "outputs": [],
   "source": [
    "import talib\n",
    "\n",
    "df['MA'] = talib.SMA(df['Close'], timeperiod=20)\n",
    "df['MACD'], df['MACD_signal'], df['MACD_hist'] = talib.MACD(df['Close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "\n",
    "df['K'], df['D'] = talib.STOCH(df['High'], df['Low'], df['Close'], fastk_period=14, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n",
    "df['J'] = 3 * df['K'] - 2 * df['D']  \n",
    "\n",
    "df['RSI'] = talib.RSI(df['Close'], timeperiod=14)\n",
    "df['OBV'] = talib.OBV(df['Close'], df['Volume']) \n",
    "\n",
    "df['BOLL_upperband'], df['BOLL_middleband'], df['BOLL_lowerband'] = talib.BBANDS(df['Close'], timeperiod=20, nbdevup=2, nbdevdn=2, matype=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UY937CeG3khA",
    "outputId": "cf25dc1f-cf5d-42b4-968c-d5bb84158d2b"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DzM5Phgj6F8k"
   },
   "outputs": [],
   "source": [
    "df['HAMMER'] = talib.CDLHAMMER(df['Open'], df['High'], df['Low'], df['Close'])\n",
    "df['HANGINGMAN'] = talib.CDLHANGINGMAN(df['Open'], df['High'], df['Low'], df['Close'])\n",
    "df['DARKCLOUDCOVER'] = talib.CDLDARKCLOUDCOVER(df['Open'], df['High'], df['Low'], df['Close'])\n",
    "df['PIERCING'] = talib.CDLPIERCING(df['Open'], df['High'], df['Low'], df['Close'])\n",
    "df['MORNINGSTAR'] = talib.CDLMORNINGSTAR(df['Open'], df['High'], df['Low'], df['Close'])\n",
    "df['EVENINGSTAR'] = talib.CDLEVENINGSTAR(df['Open'], df['High'], df['Low'], df['Close'])\n",
    "df['DOJI'] = talib.CDLDOJI(df['Open'], df['High'], df['Low'], df['Close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fY-h_EtWCKfL"
   },
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGjU3DkVVi99"
   },
   "outputs": [],
   "source": [
    "train_df= df[df['Year'] <= 2018].copy()\n",
    "test_df = df[df['Year'] >= 2019].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZzIzkxwPCRsN",
    "outputId": "22bd0a62-92e0-4592-8ab5-4c8de722b0c7"
   },
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FrlR2q2QUjVt"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train = train_df.drop(columns=['Close'])\n",
    "y_train = train_df['Close']\n",
    "X_test = test_df.drop(columns=['Close'])\n",
    "y_test = test_df['Close']\n",
    "\n",
    "\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X_train = scaler_x.fit_transform(X_train).reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test = scaler_x.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "class LSTMModel:\n",
    "    def __init__(self, input_shape, lstm_layers=2, neurons_per_layer=60, dropout_rate=0.1):\n",
    "        self.input_shape = input_shape  \n",
    "        self.lstm_layers = lstm_layers\n",
    "        self.neurons_per_layer = neurons_per_layer\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.model = self.build_lstm_model()\n",
    "\n",
    "    def build_lstm_model(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        \n",
    "        model.add(LSTM(self.neurons_per_layer, return_sequences=True, input_shape=self.input_shape))\n",
    "        model.add(Dropout(self.dropout_rate))\n",
    "\n",
    "        \n",
    "        for _ in range(self.lstm_layers - 2):\n",
    "            model.add(LSTM(self.neurons_per_layer, return_sequences=True))\n",
    "            model.add(Dropout(self.dropout_rate))\n",
    "\n",
    "      \n",
    "        model.add(LSTM(self.neurons_per_layer))\n",
    "        model.add(Dropout(self.dropout_rate))\n",
    "\n",
    "      \n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(1))  \n",
    "      \n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y, epochs, batch_size):\n",
    "        self.model.fit(X, y, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  \n",
    "\n",
    "lstm_model = LSTMModel(input_shape=input_shape, lstm_layers=2, neurons_per_layer=60, dropout_rate=0.1)\n",
    "lstm_model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "\n",
    "predicted_scaled = lstm_model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "dOUl_LdcG-Pn",
    "outputId": "9d7345db-4d9e-4e9b-cb9d-2441e0834380"
   },
   "outputs": [],
   "source": [
    "accuracy = np.mean(np.abs(predicted_scaled - y_test ) / y_test)  # Mean Absolute Error\n",
    "print(f'Mean Absolute Error: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zR7fLsRS3ubu",
    "outputId": "0e5dedd8-782c-4f3c-c0a2-e8de33c7df83"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQ2TNT2sPl1M"
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, BatchNormalization, LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "ACTOR_LR = 0.001\n",
    "CRITIC_LR = 0.002\n",
    "TAU = 0.005 \n",
    "GAMMA = 0.99  \n",
    "BUFFER_SIZE = 100000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "class PrioritizedReplayBuffer:\n",
    "    def __init__(self, capacity, alpha=0.6, beta=0.4, beta_increment=0.001):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "        self.priorities = deque(maxlen=capacity)\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.beta_increment = beta_increment\n",
    "\n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "        self.priorities.append(max(self.priorities, default=1))  \n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        total_priority_sum = sum(p**self.alpha for p in self.priorities)\n",
    "        probabilities = [(p**self.alpha) / total_priority_sum for p in self.priorities]\n",
    "        indices = random.choices(range(len(self.buffer)), weights=probabilities, k=batch_size)\n",
    "        experiences = [self.buffer[i] for i in indices]\n",
    "        weights = [(len(self.buffer) * p)**(-self.beta) for p in probabilities]\n",
    "        weights = [w / max(weights) for w in weights]  \n",
    "        self.beta = min(1, self.beta + self.beta_increment)  \n",
    "        return experiences, indices, weights\n",
    "\n",
    "    def update_priorities(self, indices, errors):\n",
    "        for i, error in zip(indices, errors):\n",
    "            self.priorities[i] = abs(error) + 1e-5  \n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "def build_actor(state_size, action_size):\n",
    "    state_input = Input(shape=(state_size,))\n",
    "    x = Dense(64, activation='relu')(state_input)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    action_output = Dense(action_size, activation='tanh')(x)\n",
    "\n",
    "    model = Model(inputs = state_input, outputs = action_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001))\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_critic(state_size, action_size):\n",
    "    state_input = Input(shape=(state_size,))\n",
    "    action_input = Input(shape=(action_size,))\n",
    "\n",
    "    state_out = Dense(64, activation='relu')(state_input)\n",
    "    state_out = Dense(64, activation='relu')(state_out)\n",
    "\n",
    "    action_out = Dense(64, activation='relu')(action_input)\n",
    "\n",
    "    x = Concatenate()([state_out, action_out])\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    Q_value_output = Dense(1)(x)\n",
    "\n",
    "    model = Model(inputs = [state_input, action_input], outputs = Q_value_output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.002), loss='mse')\n",
    "    return model\n",
    "\n",
    "class DDPGAgent:\n",
    "    def __init__(self, state_size, action_size, buffer_size=100000, batch_size=64, gamma=0.99, tau=0.001):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.buffer_size = buffer_size\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "\n",
    "        # Initialize Actor and Critic networks\n",
    "        self.memory = PrioritizedReplayBuffer(buffer_size)\n",
    "        self.actor = build_actor(state_size, action_size)\n",
    "        self.critic = build_critic(state_size, action_size)\n",
    "\n",
    "        # Initialize Target networks\n",
    "        self.target_actor = build_actor(state_size, action_size)\n",
    "        self.target_critic = build_critic(state_size, action_size)\n",
    "\n",
    "        # Synchronize Target networks\n",
    "        self.target_actor.set_weights(self.actor.get_weights())\n",
    "        self.target_critic.set_weights(self.critic.get_weights())\n",
    "\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        experience = (state, action, reward, next_state, done)\n",
    "        self.memory.add(experience)  # Add the tuple to the memory\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"Return action from Actor network (policy).\"\"\"\n",
    "        state = np.reshape(state, (1, self.state_size))\n",
    "        action = self.actor.predict(state)[0]\n",
    "        return action\n",
    "\n",
    "    def train(self):\n",
    "        if self.memory.size() < BATCH_SIZE:\n",
    "            return\n",
    "\n",
    "        # Sample a batch from experience replay\n",
    "        experiences, _, _ = self.memory.sample(BATCH_SIZE)\n",
    "\n",
    "        states = np.array([e[0] for e in experiences])\n",
    "        actions = np.array([e[1] for e in experiences])\n",
    "        rewards = np.array([e[2] for e in experiences])\n",
    "        next_states = np.array([e[3] for e in experiences])\n",
    "        dones = np.array([e[4] for e in experiences])\n",
    "        # Calculate target Q-values for Critic using Target networks\n",
    "        target_actions = self.target_actor.predict(next_states)\n",
    "        target_q_values = self.target_critic.predict([next_states, target_actions])\n",
    "        targets = rewards + GAMMA * (1 - dones) * np.squeeze(target_q_values)\n",
    "\n",
    "        # Train the Critic network\n",
    "        self.critic.train_on_batch([states, actions], targets)\n",
    "\n",
    "        # Calculate the policy gradient\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions_pred = self.actor(states)\n",
    "            critic_value = self.critic([states, actions_pred])\n",
    "            actor_loss = -tf.math.reduce_mean(critic_value)\n",
    "\n",
    "        # Update the Actor network\n",
    "        actor_grads = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
    "        self.actor.optimizer.apply_gradients(zip(actor_grads, self.actor.trainable_variables))\n",
    "\n",
    "        # Update the Target networks with soft update\n",
    "        self.update_target_network(self.target_actor, self.actor)\n",
    "        self.update_target_network(self.target_critic, self.critic)\n",
    "\n",
    "    def update_target_network(self, target_model, source_model):\n",
    "        \"\"\"Soft update the target network parameters.\"\"\"\n",
    "        target_weights = np.array(target_model.get_weights())\n",
    "        source_weights = np.array(source_model.get_weights())\n",
    "        new_weights = TAU * source_weights + (1 - TAU) * target_weights\n",
    "        target_model.set_weights(new_weights)\n",
    "\n",
    "state_size = X_train.shape[2]   \n",
    "action_size = 1  \n",
    "ddpg_agent = DDPGAgent(state_size, action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "sm3ZxEDW4h1u",
    "outputId": "01be6970-28a5-4676-86a6-1dcad6cd80e4"
   },
   "outputs": [],
   "source": [
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "collapsed": true,
    "id": "IFJHwagtAs0I",
    "outputId": "a4e57bbe-2c8d-40e7-d52b-547ad76c5794"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class StockTradingEnv(gym.Env):\n",
    "    def __init__(self, X_train, y_train, lstm_model, ddpg_agent, lambda_init=1.0, lambda_min=0.1, lambda_decay=0.9999):\n",
    "        super(StockTradingEnv, self).__init__()\n",
    "\n",
    "        self.X_train = X_train  \n",
    "        self.y_train = y_train  \n",
    "        self.max_steps = len(df)\n",
    "        self.current_step = 0\n",
    "        self.ddpg_agent = ddpg_agent\n",
    "        self.lstm_model = lstm_model\n",
    "        self.lambda_init = lambda_init  \n",
    "        self.lambda_min = lambda_min  \n",
    "        self.lambda_decay = lambda_decay  \n",
    "        self.current_lambda = lambda_init  \n",
    "        self.scaler = StandardScaler()\n",
    "        self.iteration = 0\n",
    "\n",
    "        # Portfolio initialization\n",
    "        self.initMoney = 10000\n",
    "        self.balance = self.initMoney\n",
    "        self.shares_held = 0\n",
    "        self.total_value = self.balance\n",
    "\n",
    "        # Define action and observation spaces\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)  # -1 for sell, 1 for buy\n",
    "        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(X_train.shape[1] * X_train.shape[2] ,), dtype=np.float32)  # Exclude 'Close' from observation\n",
    "\n",
    "        self.dataset_A = []\n",
    "        self.dataset_D = []\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.balance = self.initMoney\n",
    "        self.shares_held = 0\n",
    "        self.total_value = self.balance\n",
    "        self.current_lambda = self.lambda_init \n",
    "        self.dataset_A = []\n",
    "        self.dataset_D = []\n",
    "        return self.X_train[0][self.current_step].reshape(1,-1)\n",
    "\n",
    "    def get_lambda(self, iteration):\n",
    "        lambda_value = self.lambda_init * (self.lambda_decay ** iteration)\n",
    "        return max(lambda_value, self.lambda_min)  \n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "        done = False\n",
    "        if self.current_step >= self.max_steps:\n",
    "            done = True\n",
    "            self.current_step = self.max_steps - 1\n",
    "\n",
    "        current_price = self.y_train[self.current_step]\n",
    "\n",
    "        current_price = current_price.item() if isinstance(current_price, np.ndarray) else current_price\n",
    "    \n",
    "        ddpg_action = self.ddpg_agent.actor.predict(self.X_train[self.current_step].reshape(1, -1))\n",
    "\n",
    "        lstm_action = self.lstm_model.predict(self.X_train[self.current_step].reshape(1, self.X_train.shape[1], self.X_train.shape[2]))[0]\n",
    "\n",
    "        lambda_value = self.get_lambda(self.iteration)\n",
    "\n",
    "        final_action = (1 - lambda_value) * ddpg_action + lambda_value * lstm_action\n",
    "\n",
    "        if np.any(final_action) > 0:  # Buy\n",
    "            shares_to_buy = int(self.balance // current_price)\n",
    "            self.shares_held += shares_to_buy\n",
    "            self.balance -= shares_to_buy * current_price\n",
    "        elif np.any(final_action) < 0:  # Sell\n",
    "            shares_to_sell = int(self.shares_held * -final_action)\n",
    "            self.shares_held -= shares_to_sell\n",
    "            self.balance += shares_to_sell * current_price\n",
    "\n",
    "        # Calculate total value\n",
    "        self.total_value = self.balance + self.shares_held * current_price\n",
    "        earnings = self.total_value - self.initMoney\n",
    "\n",
    "        # Reward Calculation\n",
    "        if earnings > 0:\n",
    "            reward = earnings / self.initMoney\n",
    "        else:\n",
    "            reward = -0.1\n",
    "\n",
    "\n",
    "        predicted_price = self.lstm_model.predict(self.X_train[self.current_step].reshape(1, self.X_train.shape[1], self.X_train.shape[2]))[0]\n",
    "    \n",
    "        target_price = self.y_train[self.current_step]  \n",
    "        \n",
    "        supervised_reward = -abs(target_price - predicted_price)/target_price \n",
    "        reward += supervised_reward \n",
    "        \n",
    "        next_state = self.X_train[self.current_step].reshape(-1)\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "    def render(self):\n",
    "        print(f\"Step: {self.current_step}, Balance: {self.balance}, Shares Held: {self.shares_held}, Total Value: {self.total_value}\")\n",
    "\n",
    "\n",
    "env = StockTradingEnv(X_train, y_train, lstm_model, ddpg_agent)\n",
    "state = env.reset()\n",
    "\n",
    "for episode in range(100): \n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    while not done:\n",
    "\n",
    "        action = ddpg_agent.actor.predict(state.reshape(1,-1))[0]\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "        ddpg_agent.remember(state, action, reward, next_state, done)\n",
    "\n",
    "        ddpg_agent.train()\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-AMVYG4GiUC"
   },
   "outputs": [],
   "source": [
    "y_pred = ddpg_agent.predict(X_test)\n",
    "\n",
    "accuracy = np.mean(np.abs(y_pred - y_test) / y_test)  \n",
    "print(f'Mean Absolute Error: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "EjqK5TCkVMtn",
    "outputId": "b8160fb4-ec8c-48a9-e6aa-2635ff85f7e1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_df['Date'] = pd.to_datetime(test_df[['Year', 'Month', 'Day']])\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(test_df['Date'], y_test, color='blue', label='Actual Prices')\n",
    "plt.plot(test_df['Date'], predicted_scaled, color='red', label='Predicted Prices')\n",
    "plt.title('Stock Price Prediction')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
